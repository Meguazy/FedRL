\section{Closing Remarks}

This thesis demonstrates that clustered federated learning with selective layer aggregation can successfully preserve playstyle diversity in chess reinforcement learning while maintaining competitive performance. The journey from initial motivation through framework design, implementation, experimentation, and analysis has revealed both the promise and the challenges of applying federated learning to strategic domains where behavioral diversity matters.

The central insight, that moderate middle-layer sharing represents an optimal balance between knowledge transfer and specialization, challenges the conventional federated learning assumption that more sharing improves outcomes. In strategic domains, extensive sharing creates optimization conflicts that degrade performance despite providing maximum opportunities for knowledge transfer. The policy head's role as the architectural component encoding strategic identity provides a concrete design principle: preserve independence in decision-making layers while enabling collaboration in feature extraction.

A particularly striking finding is that architectural constraints, not just data heterogeneity, drive meaningful behavioral specialization. Models trained independently on disjoint datasets diverged in parameter space but converged to similar functional behaviors, while selective sharing configurations with the same data distributions achieved substantial behavioral differentiation. This reveals that diversity in distributed learning systems emerges from the interaction between data, architecture, and optimization constraints rather than from data distribution differences alone.

These findings have implications extending beyond chess and federated learning. In multi-agent reinforcement learning, the framework suggests architectures for maintaining agent diversity in cooperative settings where homogeneous strategies lead to vulnerabilities. In transfer learning, the hierarchical knowledge transfer hypothesis, that different network layers benefit differently from sharing, informs which components to transfer versus fine-tune when adapting models across tasks. In personalized federated learning, the performance-diversity trade-off quantifies the inherent tension between global model quality and user-specific customization.

The broader vision is a future where distributed AI systems can collaborate without sacrificing the diversity that makes them robust and adaptable. Just as ecological diversity creates resilient ecosystems, behavioral diversity in AI systems provides resilience against adversarial attacks, environment shifts, and unforeseen challenges. A team of specialized chess engines, each mastering different playing styles while sharing fundamental chess understanding, could collectively outperform any single general-purpose system by selecting the appropriate specialist for each opponent and situation.

This research represents a step toward that vision. We have demonstrated technical feasibility, identified critical architectural properties, quantified fundamental trade-offs, and established methodological standards for evaluating behavioral diversity alongside performance. The challenges that remain, scaling to more clusters, validating across domains, integrating with self-play, optimizing sharing policies adaptively, are well-defined research directions building on solid foundations.

The intersection of federated learning and reinforcement learning is still nascent, with many open questions about how distributed agents can learn collaboratively while maintaining individual identities. Strategic games provide an ideal testbed where diversity is measurable, valuable, and theoretically interesting. As AI systems increasingly operate in multi-agent environments requiring both cooperation and specialization, the principles uncovered in this chess framework, selective sharing, architectural constraints driving specialization, the performance-diversity trade-off, will inform designs across domains.

The ultimate measure of success for this research is not merely the specific findings about chess or federated learning, but the questions it raises and the paths it opens for future investigation. If this work inspires researchers to explore selective aggregation in other domains, develop theoretical foundations for partial parameter sharing, or design adaptive systems that dynamically balance collaboration and specialization, then it will have achieved its broader purpose.

Clustered federated learning with selective aggregation is not a complete solution to preserving diversity in distributed AI, but it is a promising direction. The framework, implementation, experimental findings, and lessons learned provide tools and insights for the next generation of researchers tackling these challenges. The game of chess taught humanity about strategy, planning, and decision-making for centuries. Perhaps it can also teach our AI systems how to collaborate while maintaining their individual strategic identities.
