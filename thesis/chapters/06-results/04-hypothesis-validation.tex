\section{Hypothesis Validation}

This section systematically evaluates each research hypothesis against the experimental evidence. We provide statistical validation where applicable and assess whether the observed results support, reject, or partially support each hypothesis. The hypotheses are organized into performance, behavioral, and system categories.

\subsection{Performance Hypotheses}

\subsubsection{H1: Clustered FL Outperforms Centralized Training}

\textbf{Hypothesis}: Clustered federated learning with partial layer sharing (P1-P4) achieves higher playing strength (ELO rating) compared to the centralized full sharing baseline (B1).

\textbf{Result}: Mixed support. Three of four partial sharing configurations outperform B1, but one configuration shows substantial underperformance.

The evidence shows P2 outperforms B1 by 125 ELO points (1137.5 vs 1012.5), representing a 12.3\% improvement. P1 exceeds B1 by 87.5 ELO (1100.0 vs 1012.5), an 8.6\% improvement. Even P3, despite its specialization failure, surpasses B1 by 37.5 ELO (1050.0 vs 1012.5). However, P4 dramatically underperforms B1 by 75 ELO points (937.5 vs 1012.5), falling 7.4\% below the baseline.

\textbf{Conclusion}: Clustered federated learning with partial sharing can outperform centralized training, but success critically depends on appropriate layer selection. Moderate sharing (P2 at 32\% of parameters, P1 at 23\%) improves performance, while excessive sharing (P4 at 86\%) proves counterproductive. The hypothesis is supported for well-designed configurations but rejected for poorly chosen sharing strategies.

\subsubsection{H2: Selective Aggregation Improves Cluster Models}

\textbf{Hypothesis}: Selective layer aggregation enables controlled specialization, with parameter divergence falling between the full sharing baseline (B1, near-zero divergence) and no sharing baseline (B2, maximum divergence).

\textbf{Result}: Strongly supported across multiple metrics.

Parameter divergence analysis confirms that partial sharing configurations achieve intermediate specialization levels. Policy head divergence shows B1 at approximately 0.00 (forced synchronization), B2 at 0.23 (independent evolution), and partial sharing configurations at 0.21-0.22 (P1, P2, P4), falling precisely in the predicted intermediate range. Value head divergence demonstrates even stronger gradation: B1 at 0.00, B2 at 0.74, P1 at 1.18, and P2 at 1.57.

P3's zero head divergence validates that shared heads prevent specialization regardless of backbone differences, while P1, P2, and P4 demonstrate that selective aggregation successfully balances knowledge transfer (via shared layers) with specialization capacity (via independent layers). The monotonic relationship between sharing extent and divergence confirms that selective aggregation provides fine-grained control over the performance-diversity trade-off.

\textbf{Conclusion}: Hypothesis strongly supported. Selective aggregation successfully creates controlled specialization gradients, enabling system designers to tune the balance between knowledge sharing and behavioral diversity through architectural choices.

\subsubsection{H3: Cross-Cluster Learning Enables Knowledge Transfer}

\textbf{Hypothesis}: Partial layer sharing enables beneficial cross-cluster knowledge transfer, allowing configurations with shared layers to outperform the no-sharing baseline (B2).

\textbf{Result}: Rejected at final round, but supported when considering average performance across training.

At round 350, B2 achieves the highest final ELO at 1150.0, surpassing the best partial sharing configuration (P2) by 12.5 points. P1 falls 50 points below B2, and P4 trails by 212.5 points. This suggests that complete independence allows models to optimize further than configurations constrained by periodic aggregation.

However, when examining average ELO across all 200 training rounds, P2 achieves 926.1 compared to B2's 922.9, indicating that middle-layer sharing provides better training stability and sample efficiency during early and mid-training phases. This suggests a trade-off: shared layers accelerate initial learning and improve average performance, but may impose optimization constraints that limit final performance compared to unconstrained independent training.

\textbf{Conclusion}: The hypothesis is rejected for final performance but supported for training efficiency. Cross-cluster learning through partial sharing improves sample efficiency and stability during training but does not enable configurations to surpass fully independent training at convergence. The benefit lies in learning dynamics rather than ultimate performance.

\subsection{Behavioral Hypotheses}

\subsubsection{H4: Playstyle Clusters Emerge Naturally}

\textbf{Hypothesis}: Training on games from different opening classifications (tactical versus positional ECO codes) creates measurable playstyle differences between clusters.

\textbf{Result}: Partially supported, with emergence success critically dependent on policy head independence.

Behavioral separation metrics reveal stark differences across configurations. P1, P2, and P4 successfully develop distinct playstyles with tactical score differences of 0.91, 1.51, and 1.95 respectively, indicating moderate to very strong specialization. In contrast, B1, B2, and P3 show minimal separation at 0.23, 0.20, and -0.02, representing complete failure to develop distinct behaviors despite training on games from disjoint opening classifications.

The critical factor is policy head architecture. All configurations with independent policy heads (P1, P2, P4) successfully specialize, while configurations with shared policy heads (B1, P3) fail completely. Surprisingly, B2's complete independence also fails to produce strong specialization, suggesting that architectural constraints (like partial sharing forcing differentiation) may be necessary to drive behavioral divergence beyond what emerges naturally from data distribution differences alone.

\textbf{Conclusion}: Hypothesis partially supported. Playstyle emergence is possible but requires specific architectural properties, namely independent policy heads combined with appropriate sharing constraints. Training distribution alone is insufficient; the architecture must permit and encourage specialization through controlled aggregation.

\subsubsection{H5: Different Clusters Develop Distinct Strategies}

\textbf{Hypothesis}: Tactical and positional clusters exhibit different strategic preferences in move type selection, with tactical clusters favoring aggressive moves and captures while positional clusters prefer quiet strategic moves.

\textbf{Result}: Supported for configurations with successful specialization (P1, P2, P4).

Move type analysis confirms substantial strategic differences in specialized configurations. P4 shows tactical clusters playing 1.95\% more aggressive moves, 1.10\% more captures, and 2.49\% fewer quiet moves compared to positional clusters. P2 demonstrates 1.51\% more aggressive moves, 0.55\% more captures, and 1.35\% fewer quiet moves. P1 exhibits 0.91\% more aggressive moves and 0.98\% more captures.

These differences achieve large effect sizes (Cohen's d > 0.5) for P2 and P4, indicating practically significant behavioral distinctions. The patterns align precisely with the training distributions: tactical clusters trained on games from sharp tactical openings (Sicilian Defence, King's Gambit) adopt forcing, aggressive playstyles, while positional clusters trained on games from strategic positional openings (Queen's Gambit, Nimzo-Indian) favor patient, positional approaches.

In contrast, B1, B2, and P3 show negligible strategic differences (0.20-0.23\% in aggressive moves), confirming that failed specialization produces homogeneous strategies regardless of training distribution.

\textbf{Conclusion}: Hypothesis strongly supported for configurations with independent policy heads. Distinct strategic preferences emerge as predicted, with tactical clusters favoring forcing moves and positional clusters preferring strategic positioning. The effect sizes exceed conventional thresholds for practical significance.

\subsubsection{H6: Behavioral Differences Are Measurable}

\textbf{Hypothesis}: The evaluation framework can detect meaningful behavioral differences between clusters through multiple complementary metrics.

\textbf{Result}: Strongly supported across diverse measurement approaches.

Multiple independent metrics successfully capture behavioral separation. Tactical score differences range from 0.91 to 1.95 for specialized configurations, clearly distinguishing successful (P1, P2, P4) from failed (B1, B2, P3) specialization. Aggressive move percentages show 0.91-1.95 percentage point differences, quiet move percentages differ by 0.65-2.49 percentage points, and policy head divergence ranges from 0.21-0.23 for specialized configurations versus near-zero for homogeneous ones.

The metrics exhibit strong inter-correlation, with behavioral separation (tactical score) correlating positively with move type differences and parameter divergence. This convergent validity across multiple measurement approaches confirms that the observed differences represent genuine behavioral distinctions rather than measurement artifacts.

Effect sizes exceed Cohen's d > 0.5 thresholds for P2 and P4 across multiple metrics, demonstrating that the differences are both statistically significant and practically meaningful. The evaluation framework successfully distinguishes configurations with large behavioral separations, moderate separations, and failed specialization.

\textbf{Conclusion}: Hypothesis strongly supported. The multi-metric evaluation framework reliably detects and quantifies behavioral differences across diverse measurement dimensions, providing robust validation of playstyle specialization.

\subsection{System Hypotheses}

\subsubsection{H7: Clusters Maintain Stability Over Training}

\textbf{Hypothesis}: Cluster divergence stabilizes during training and maintains separation without reconverging to homogeneous behaviors.

\textbf{Result}: Supported, with clear plateau behavior observed in all specialized configurations.

Policy head divergence trajectories demonstrate consistent stabilization patterns. All configurations with independent policy heads (B2, P1, P2, P4) exhibit rapid initial divergence decrease from rounds 10-100 (P2: 0.32 to 0.26), gradual stabilization from rounds 100-200 (P2: 0.26 to 0.23), and plateau behavior from rounds 200-350 (P2: 0.23 to 0.22).

The plateau after round 200 indicates that specialization solidifies and persists through extended training. No configuration shows reconvergence, the divergence values stabilize rather than decreasing toward zero. This validates that federated aggregation with selective sharing creates stable specialization rather than transient training artifacts that eventually collapse to homogeneity.

B1 and P3 maintain zero divergence throughout training due to shared policy heads, confirming that forced synchronization prevents any emergence of specialization regardless of training duration. The stability of non-zero divergence in P1, P2, and P4 demonstrates that architectural choices determine long-term behavioral outcomes.

\textbf{Conclusion}: Hypothesis strongly supported. Clusters maintain stable specialization over extended training without reconverging. The plateau pattern confirms that selective layer aggregation creates persistent behavioral diversity rather than temporary divergence that eventually disappears.
