# P4: Share Backbone, Separate Heads - Selective Aggregation Experiment
# Tests hypothesis that playstyle divergence can emerge from separate heads alone
# when sharing entire backbone (input + all residual blocks)

experiment_name: "P4_share_backbone"
description: "Share input and all residual blocks (0-18), only heads cluster-specific"

# Training parameters
num_rounds: 500
checkpoint_interval: 5

# Server configuration
server_config:
  host: "localhost"
  port: 8765

# Orchestrator configuration - Share Entire Backbone
orchestrator_config:
  aggregation_threshold: 0.8
  timeout_seconds: 1200              # 20 minutes for supervised training

  # P4: Share input + ALL residual blocks (0-18)
  shared_layer_patterns:
    - "input_conv.*"           # Input layers shared
    - "input_bn.*"
    - "res_blocks.0.*"         # ALL 19 residual blocks shared
    - "res_blocks.1.*"
    - "res_blocks.2.*"
    - "res_blocks.3.*"
    - "res_blocks.4.*"
    - "res_blocks.5.*"
    - "res_blocks.6.*"
    - "res_blocks.7.*"
    - "res_blocks.8.*"
    - "res_blocks.9.*"
    - "res_blocks.10.*"
    - "res_blocks.11.*"
    - "res_blocks.12.*"
    - "res_blocks.13.*"
    - "res_blocks.14.*"
    - "res_blocks.15.*"
    - "res_blocks.16.*"
    - "res_blocks.17.*"
    - "res_blocks.18.*"

  # Cluster-specific: ONLY the heads
  cluster_specific_patterns:
    - "policy_head.*"          # Policy head cluster-specific
    - "value_head.*"           # Value head cluster-specific

# Playstyle evaluation configuration
evaluation_config:
  enabled: true
  interval_rounds: 10
  games_per_elo_level: 10
  stockfish_elo_levels: [1000, 1200, 1400]
  time_per_move: 0.1
  skip_check_positions: true
  stockfish_path: null

  # Enhanced metrics
  enable_delta_analysis: true
  delta_sampling_rate: 3
  stockfish_depth: 12

# Cluster topology (defined in cluster_topology.yaml but documented here for reference)
# cluster_tactical:
#   node_count: 4
#   games_per_round: 400 (per node)
#   playstyle: "tactical"
#   Total games per round: 4 nodes × 400 games = 1600 games
#   Shared layers: input + ALL res_blocks 0-18 (entire backbone)
#   Independent layers: ONLY heads (2 heads)
#
# cluster_positional:
#   node_count: 4
#   games_per_round: 400 (per node)
#   playstyle: "positional"
#   Total games per round: 4 nodes × 400 games = 1600 games
#   Shared layers: input + ALL res_blocks 0-18 (entire backbone)
#   Independent layers: ONLY heads (2 heads)
#
# Total training data per round: 3200 games (1600 tactical + 1600 positional)
# Total training data for 500 rounds: 1,600,000 games

# Expected outcomes for P4:
# - Moderate-to-high global divergence (cosine similarity 0.75-0.85 for heads)
# - Moderate playstyle separation (tactical score difference 0.10-0.15)
# - Likely highest ELO (1400-1600) due to maximum shared knowledge
# - Tactical cluster: moderate-high tactical score (0.58-0.63), some aggression
# - Positional cluster: moderate tactical score (0.48-0.53), some strategy
# - ENTIRE backbone converges (shared), only heads diverge
# - Tests MINIMUM divergence architecture for playstyle differentiation
# - Critical question: Can separate heads alone achieve sufficient divergence?
# - Expected to perform between B1 (full sharing) and P1/P2 (partial sharing)
# - Most parameter-efficient approach (only 2 heads differ vs full models)
