# P1: Share Early Layers Only - Selective Aggregation Experiment
# Tests hypothesis that sharing early feature extraction while allowing independent
# mid-level and high-level specialization enables playstyle divergence

experiment_name: "P1_share_early"
description: "Share input and early residual blocks (0-5), independent mid/late layers and heads"

# Training parameters
num_rounds: 500
checkpoint_interval: 5

# Server configuration
server_config:
  host: "localhost"
  port: 8765

# Orchestrator configuration - Share Early Layers
orchestrator_config:
  aggregation_threshold: 0.8
  timeout_seconds: 1200              # 20 minutes for supervised training

  # P1: Share input + early residual blocks (0-5)
  shared_layer_patterns:
    - "input_conv.*"
    - "input_bn.*"
    - "res_blocks.0.*"         # Early feature extraction (blocks 0-5)
    - "res_blocks.1.*"
    - "res_blocks.2.*"
    - "res_blocks.3.*"
    - "res_blocks.4.*"
    - "res_blocks.5.*"

  # Cluster-specific: Middle/late blocks and heads
  cluster_specific_patterns:
    - "res_blocks.6.*"         # Middle and late blocks (6-18)
    - "res_blocks.7.*"
    - "res_blocks.8.*"
    - "res_blocks.9.*"
    - "res_blocks.10.*"
    - "res_blocks.11.*"
    - "res_blocks.12.*"
    - "res_blocks.13.*"
    - "res_blocks.14.*"
    - "res_blocks.15.*"
    - "res_blocks.16.*"
    - "res_blocks.17.*"
    - "res_blocks.18.*"
    - "policy_head.*"          # Heads remain cluster-specific
    - "value_head.*"

# Playstyle evaluation configuration
evaluation_config:
  enabled: true
  interval_rounds: 10
  games_per_elo_level: 10
  stockfish_elo_levels: [1000, 1200, 1400]
  time_per_move: 0.1
  skip_check_positions: true
  stockfish_path: null

  # Enhanced metrics
  enable_delta_analysis: true
  delta_sampling_rate: 3
  stockfish_depth: 12

# Cluster topology (defined in cluster_topology.yaml but documented here for reference)
# cluster_tactical:
#   node_count: 4
#   games_per_round: 400 (per node)
#   playstyle: "tactical"
#   Total games per round: 4 nodes × 400 games = 1600 games
#   Shared layers: input + res_blocks 0-5 (6 shared blocks)
#   Independent layers: res_blocks 6-18 + heads (13 independent blocks + 2 heads)
#
# cluster_positional:
#   node_count: 4
#   games_per_round: 400 (per node)
#   playstyle: "positional"
#   Total games per round: 4 nodes × 400 games = 1600 games
#   Shared layers: input + res_blocks 0-5 (6 shared blocks)
#   Independent layers: res_blocks 6-18 + heads (13 independent blocks + 2 heads)
#
# Total training data per round: 3200 games (1600 tactical + 1600 positional)
# Total training data for 500 rounds: 1,600,000 games

# Expected outcomes for P1:
# - Moderate global divergence (cosine similarity 0.7-0.8 for heads)
# - Good playstyle separation (tactical score difference 0.10-0.15)
# - Potentially improved ELO (1300-1500) due to shared low-level features
# - Tactical cluster: higher tactical score (> 0.60), calculated aggression
# - Positional cluster: lower tactical score (< 0.55), strategic patience
# - Early layers converge (shared), mid/late layers and heads diverge
# - Tests if sharing basic pattern recognition improves both playstyles
